MACHINE LEARNING – WORKSHEET 4
In Q1 to Q8, only one option is correct, Choose the correct option:
1. Which of the following in sklearn library is used for hyper parameter tuning?
A) GridSearchCV() B) RandomizedCV()
C) K-fold Cross Validation D) None of the above
Ans: (A) GridSearchCV()

2. In which of the below ensemble techniques trees are trained in parallel?
A) Random forest B) Adaboost
C) Gradient Boosting D) All of the above
Ans: (A) Random forest

3. In machine learning, if in the below line of code:
sklearn.svm.SVC (C=1.0, kernel='rbf', degree=3)
we increasing the C hyper parameter, what will happen?
A) The regularization will increase B) The regularization will decrease
C) No effect on regularization D) kernel will be changed to linear
Ans:  (B) The regularization will decrease

4. Check the below line of code and answer the following questions:
sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2)
Which of the following is true regarding max_depth hyper parameter?
A) It regularizes the decision tree by limiting the maximum depth up to which a tree can be grown.
B) It denotes the number of children a node can have.
C) both A & B
D) None of the above
Ans: (A) It regularizes the decision tree by limiting the maximum depth up to which a tree can be grown.


5. Which of the following is true regarding Random Forests?
A) It's an ensemble of weak learners.
B) The component trees are trained in series
C) In case of classification problem, the prediction is made by taking mode of the class labels predicted by the component trees.
D)None of the above
Ans: (A) It's an ensemble of weak learners. 

6. What can be the disadvantage if the learning rate is very high in gradient descent?
A) Gradient Descent algorithm can diverge from the optimal solution.
B) Gradient Descent algorithm can keep oscillating around the optimal solution and may not settle.
C) Both of them
D)None of them.
Ans: (C) Both of them

7. As the model complexity increases, what will happen?
A) Bias will increase, Variance decrease B) Bias will decrease, Variance increase
C)both bias and variance increase D) Both bias and variance decrease.
Ans:  (B) Bias will decrease, Variance increase

8. Suppose I have a linear regression model which is performing as follows:
Train accuracy=0.95
Test accuracy=0.75
Which of the following is true regarding the model?
A) model is underfitting B) model is overfitting
C) model is performing good D) None of the above
Ans: (B) model is overfitting

Q9 to Q15 are subjective answer type questions, Answer them briefly.
9. Suppose we have a dataset which have two classes A and B. The percentage of class A is 40% and percentage of class B is 60%. Calculate the Gini index and entropy of the dataset.
Ans: 

10. What are the advantages of Random Forests over Decision Tree?
Ans: Random Forests aggregate many decision trees to limit overfitting as well as error due to bias and therefore yield useful results over a single Decision Tree.

11. What is the need of scaling all numerical features in a dataset? Name any two techniques used for scaling.
Ans: Machine learning algorithms just see numbers — if there is a vast difference in the range say few ranging in thousands and few ranging in the tens, then it makes the underlying assumption that higher ranging numbers have superiority of some sort. So these more significant numbers start playing a more decisive role while training the model. To avoid this bias.. we scale the dataset. 
Techniques used for scaling - Min max scaler and Standard scalar

12. Write down some advantages which scaling provides in optimization using gradient descent algorithm.
Ans:  We can speed up gradient descent by scaling because θ reduces quickly on small ranges and slowly on large ranges, and oscillates inefficiently down to the optimum when the variables are very uneven. 

13. In case of a highly imbalanced dataset for a classification problem, is accuracy a good metric to measure the performance of the model. If not, why?
Ans:  No Accuracy is not a good metric to measure the performance of a highly imbalanced dataset as a high accuracy (or low error) is achievable by a no skill model that only predicts the majority class

14. What is “f-score" metric? Write its mathematical formula.
Ans:  "F-score" is the weighted avg. of precision and Recall. 
Formula: 
F1 Score = 2*((precision*recall)/(precision+recall)).

15. What is the difference between fit(), transform() and fit_transform()?
Ans:  sklearn's transform's fit() just calculates the parameters and saves them as an internal object's state. Post that, we can call its transform() method to apply the transformation to our dataset
fit_transform() joins these two steps and is used for the initial fitting of parameters on the training set, while also returning the transformed set. Internally, the transformer object just calls first fit() and then transform() on the same data


